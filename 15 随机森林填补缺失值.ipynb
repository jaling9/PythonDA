{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入需要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.impute import SimpleImputer # 填补缺失值\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mjl\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_boston()\n",
    "dataset.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入完整的数据集并探索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#总共506*13=6578个数据\n",
    "X_full, y_full = dataset.data, dataset.target\n",
    "n_samples = X_full.shape[0]\n",
    "n_features = X_full.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples # 样本数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features # 特征数量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为完整数据集放入缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#首先确定我们希望放入的缺失数据的比例，在这里我们假设是50%，那总共就要有3289个数据缺失\n",
    "rng = np.random.RandomState(0)\n",
    "missing_rate = 0.5\n",
    "n_missing_samples = int(np.floor(n_samples * n_features * missing_rate))\n",
    "#np.floor向下取整，返回.0格式的浮点数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#所有数据要随机遍布在数据集的各行各列当中，而一个缺失的数据会需要一个行索引和一个列索引\n",
    "#如果能够创造一个数组，包含3289个分布在0~506中间的行索引，和3289个分布在0~13之间的列索引，那我们就可\n",
    "#以利用索引来为数据中的任意3289个位置赋空值\n",
    "#然后我们用0，均值和随机森林来填写这些缺失值，然后查看回归的结果如何\n",
    "missing_features = rng.randint(0,n_features,n_missing_samples)\n",
    "missing_samples = rng.randint(0,n_samples,n_missing_samples)\n",
    "#missing_samples = rng.choice(dataset.data.shape[0],n_missing_samples,replace=False)\n",
    "#我们现在采样了3289个数据，远远超过我们的样本量506，所以我们使用随机抽取的函数randint。但如果我们需要\n",
    "#的数据量小于我们的样本量506，那我们可以采用np.random.choice来抽样，choice会随机抽取不重复的随机数，\n",
    "#因此可以帮助我们让数据更加分散，确保数据不会集中在一些行中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12,  5,  0, ..., 11,  0,  2])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150 125  28 ... 132 456 402]\n",
      "3289\n"
     ]
    }
   ],
   "source": [
    "print(missing_samples)\n",
    "print(len(missing_samples))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_missing = X_full.copy()\n",
    "y_missing = y_full.copy()\n",
    "\n",
    "X_missing[missing_samples,missing_features] = np.nan\n",
    "X_missing = pd.DataFrame(X_missing)\n",
    "#转换成DataFrame是为了后续方便各种操作，numpy对矩阵的运算速度快到拯救人生，但是在索引等功能上却不如\n",
    "#pandas来得好用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>69.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>89.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2    3      4      5     6       7    8      9     10  \\\n",
       "0        NaN  18.0    NaN  NaN  0.538    NaN  65.2  4.0900  1.0  296.0   NaN   \n",
       "1    0.02731   0.0    NaN  0.0  0.469    NaN  78.9  4.9671  2.0    NaN   NaN   \n",
       "2    0.02729   NaN   7.07  0.0    NaN  7.185  61.1     NaN  2.0  242.0   NaN   \n",
       "3        NaN   NaN    NaN  0.0  0.458    NaN  45.8     NaN  NaN  222.0  18.7   \n",
       "4        NaN   0.0   2.18  0.0    NaN  7.147   NaN     NaN  NaN    NaN  18.7   \n",
       "..       ...   ...    ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
       "501      NaN   NaN    NaN  0.0  0.573    NaN  69.1     NaN  1.0    NaN  21.0   \n",
       "502  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  273.0   NaN   \n",
       "503      NaN   NaN  11.93  NaN  0.573  6.976  91.0     NaN  NaN    NaN  21.0   \n",
       "504  0.10959   0.0  11.93  NaN  0.573    NaN  89.3     NaN  1.0    NaN  21.0   \n",
       "505  0.04741   0.0  11.93  0.0  0.573  6.030   NaN     NaN  1.0    NaN   NaN   \n",
       "\n",
       "         11    12  \n",
       "0       NaN  4.98  \n",
       "1    396.90  9.14  \n",
       "2       NaN   NaN  \n",
       "3       NaN   NaN  \n",
       "4       NaN  5.33  \n",
       "..      ...   ...  \n",
       "501     NaN  9.67  \n",
       "502  396.90  9.08  \n",
       "503     NaN  5.64  \n",
       "504  393.45  6.48  \n",
       "505  396.90  7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用均值进行填补"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1      2      3      4      5      6      7      8      9      10     11     12   \n",
       "False  False  False  False  False  False  False  False  False  False  False  False  False    506\n",
       "dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用0和均值填补缺失值\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan,strategy='mean') # 实例化\n",
    "X_missing_mean = imp_mean.fit_transform(X_missing) # 训练+导出\n",
    "pd.DataFrame(X_missing_mean).isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用0进行填补"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1      2      3      4      5      6      7      8      9      10     11     12   \n",
       "False  False  False  False  False  False  False  False  False  False  False  False  False    506\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#使用0进行填补\n",
    "imp_0 = SimpleImputer(missing_values=np.nan, strategy=\"constant\",fill_value=0)\n",
    "X_missing_0 = imp_0.fit_transform(X_missing)\n",
    "pd.DataFrame(X_missing_mean).isnull().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随机森林填充缺失值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "使用随机森林回归填补缺失值\n",
    "任何回归都是从特征矩阵中学习，然后求解连续型标签y的过程，之所以能够实现这个过程，是因为回归算法认为，特征\n",
    "矩阵和标签之前存在着某种联系。实际上，标签和特征是可以相互转换的，比如说，在一个“用地区，环境，附近学校数\n",
    "量”预测“房价”的问题中，我们既可以用“地区”，“环境”，“附近学校数量”的数据来预测“房价”，也可以反过来，\n",
    "用“环境”，“附近学校数量”和“房价”来预测“地区”。而回归填补缺失值，正是利用了这种思想。\n",
    "\n",
    "对于一个有n个特征的数据来说，其中特征T有缺失值，我们就把特征T当作标签，其他的n-1个特征和原本的标签组成新\n",
    "的特征矩阵。那对于T来说，它没有缺失的部分，就是我们的Y_test，这部分数据既有标签也有特征，而它缺失的部\n",
    "分，只有特征没有标签，就是我们需要预测的部分。\n",
    "\n",
    "特征T不缺失的值对应的其他n-1个特征 + 本来的标签：X_train\n",
    "特征T不缺失的值：Y_train\n",
    "特征T缺失的值对应的其他n-1个特征 + 本来的标签：X_test\n",
    "特征T缺失的值：未知，我们需要预测的Y_test\n",
    "这种做法，对于某一个特征大量缺失，其他特征却很完整的情况，非常适用。\n",
    "\n",
    "那如果数据中除了特征T之外，其他特征也有缺失值怎么办？\n",
    "答案是遍历所有的特征，从缺失最少的开始进行填补（因为填补缺失最少的特征所需要的准确信息最少）。\n",
    "填补一个特征时，先将其他特征的缺失值用0代替，每完成一次回归预测，就将预测值放到原本的特征矩阵中，再继续填\n",
    "补下一个特征。每一次填补完毕，有缺失值的特征会减少一个，所以每次循环后，需要用0来填补的特征就越来越少。当\n",
    "进行到最后一个特征时（这个特征应该是所有特征中缺失值最多的），已经没有任何的其他特征需要用0来进行填补了，\n",
    "而我们已经使用回归为其他特征填补了大量有效信息，可以用来填补缺失最多的特征。\n",
    "遍历所有的特征后，数据就完整，不再有缺失值了。\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_missing_reg = X_missing.copy()\n",
    "sortindex = np.argsort(X_missing_reg.isnull().sum(axis=0)).values\n",
    "# 返回排序顺序所对应的索引\n",
    "# 找到需要被填充的列的索引，并按从小到大排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 12,  8,  7,  9,  0,  2,  1,  5,  4,  3, 10, 11], dtype=int64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sortindex:\n",
    "    #构建我们的新特征矩阵和新标签\n",
    "    df = X_missing_reg\n",
    "    fillc = df.iloc[:,i]\n",
    "    df = pd.concat([df.iloc[:,df.columns != i],pd.DataFrame(y_full)],axis=1)\n",
    "\n",
    "    #在新特征矩阵中，对含有缺失值的列，进行0的填补\n",
    "    df_0 =SimpleImputer(missing_values=np.nan,strategy='constant',fill_value=0).fit_transform(df)\n",
    "\n",
    "    #找出我们的训练集和测试集\n",
    "    Ytrain = fillc[fillc.notnull()] # 非空值是训练集\n",
    "    Ytest = fillc[fillc.isnull()]   # 空值是（需要填充的值）\n",
    "    Xtrain = df_0[Ytrain.index,:]   # Ytrain.index是训练集索引\n",
    "    Xtest = df_0[Ytest.index,:]     # Ytest.index是测试集索引 \n",
    "\n",
    "    #用随机森林回归来填补缺失值\n",
    "    rfc = RandomForestRegressor(n_estimators=100)\n",
    "    rfc = rfc.fit(Xtrain, Ytrain)\n",
    "    Ypredict = rfc.predict(Xtest)\n",
    "    \n",
    "    #将填补好的特征返回到我们的原始的特征矩阵中\n",
    "    X_missing_reg.loc[X_missing_reg.iloc[:,i].isnull(),i] = Ypredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.304817</td>\n",
       "      <td>18.000</td>\n",
       "      <td>6.9296</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.65685</td>\n",
       "      <td>65.200</td>\n",
       "      <td>4.090000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>296.00</td>\n",
       "      <td>18.530</td>\n",
       "      <td>388.1114</td>\n",
       "      <td>4.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.027310</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.0963</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.469000</td>\n",
       "      <td>6.12501</td>\n",
       "      <td>78.900</td>\n",
       "      <td>4.967100</td>\n",
       "      <td>2.00</td>\n",
       "      <td>304.21</td>\n",
       "      <td>18.554</td>\n",
       "      <td>396.9000</td>\n",
       "      <td>9.1400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.027290</td>\n",
       "      <td>7.760</td>\n",
       "      <td>7.0700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.467759</td>\n",
       "      <td>7.18500</td>\n",
       "      <td>61.100</td>\n",
       "      <td>4.376986</td>\n",
       "      <td>2.00</td>\n",
       "      <td>242.00</td>\n",
       "      <td>18.122</td>\n",
       "      <td>387.5477</td>\n",
       "      <td>5.2185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.092003</td>\n",
       "      <td>20.790</td>\n",
       "      <td>3.1591</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.458000</td>\n",
       "      <td>6.93309</td>\n",
       "      <td>45.800</td>\n",
       "      <td>4.768734</td>\n",
       "      <td>3.59</td>\n",
       "      <td>222.00</td>\n",
       "      <td>18.700</td>\n",
       "      <td>392.9529</td>\n",
       "      <td>5.9171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.085509</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.1800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.468835</td>\n",
       "      <td>7.14700</td>\n",
       "      <td>57.902</td>\n",
       "      <td>4.887509</td>\n",
       "      <td>3.88</td>\n",
       "      <td>245.88</td>\n",
       "      <td>18.700</td>\n",
       "      <td>392.2296</td>\n",
       "      <td>5.3300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.493297</td>\n",
       "      <td>2.285</td>\n",
       "      <td>10.6825</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>6.25453</td>\n",
       "      <td>69.100</td>\n",
       "      <td>3.177907</td>\n",
       "      <td>1.00</td>\n",
       "      <td>286.43</td>\n",
       "      <td>21.000</td>\n",
       "      <td>390.4549</td>\n",
       "      <td>9.6700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.045270</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.9300</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>6.12000</td>\n",
       "      <td>76.700</td>\n",
       "      <td>2.287500</td>\n",
       "      <td>1.00</td>\n",
       "      <td>273.00</td>\n",
       "      <td>19.329</td>\n",
       "      <td>396.9000</td>\n",
       "      <td>9.0800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.556385</td>\n",
       "      <td>0.250</td>\n",
       "      <td>11.9300</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>6.97600</td>\n",
       "      <td>91.000</td>\n",
       "      <td>2.637837</td>\n",
       "      <td>3.72</td>\n",
       "      <td>312.44</td>\n",
       "      <td>21.000</td>\n",
       "      <td>389.8756</td>\n",
       "      <td>5.6400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.109590</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.9300</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>6.40112</td>\n",
       "      <td>89.300</td>\n",
       "      <td>2.734656</td>\n",
       "      <td>1.00</td>\n",
       "      <td>243.71</td>\n",
       "      <td>21.000</td>\n",
       "      <td>393.4500</td>\n",
       "      <td>6.4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.047410</td>\n",
       "      <td>0.000</td>\n",
       "      <td>11.9300</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.573000</td>\n",
       "      <td>6.03000</td>\n",
       "      <td>87.343</td>\n",
       "      <td>2.805761</td>\n",
       "      <td>1.00</td>\n",
       "      <td>315.70</td>\n",
       "      <td>18.969</td>\n",
       "      <td>396.9000</td>\n",
       "      <td>7.8800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0       1        2     3         4        5       6         7   \\\n",
       "0    0.304817  18.000   6.9296  0.11  0.538000  6.65685  65.200  4.090000   \n",
       "1    0.027310   0.000   5.0963  0.00  0.469000  6.12501  78.900  4.967100   \n",
       "2    0.027290   7.760   7.0700  0.00  0.467759  7.18500  61.100  4.376986   \n",
       "3    0.092003  20.790   3.1591  0.00  0.458000  6.93309  45.800  4.768734   \n",
       "4    0.085509   0.000   2.1800  0.00  0.468835  7.14700  57.902  4.887509   \n",
       "..        ...     ...      ...   ...       ...      ...     ...       ...   \n",
       "501  0.493297   2.285  10.6825  0.00  0.573000  6.25453  69.100  3.177907   \n",
       "502  0.045270   0.000  11.9300  0.00  0.573000  6.12000  76.700  2.287500   \n",
       "503  0.556385   0.250  11.9300  0.25  0.573000  6.97600  91.000  2.637837   \n",
       "504  0.109590   0.000  11.9300  0.03  0.573000  6.40112  89.300  2.734656   \n",
       "505  0.047410   0.000  11.9300  0.00  0.573000  6.03000  87.343  2.805761   \n",
       "\n",
       "       8       9       10        11      12  \n",
       "0    1.00  296.00  18.530  388.1114  4.9800  \n",
       "1    2.00  304.21  18.554  396.9000  9.1400  \n",
       "2    2.00  242.00  18.122  387.5477  5.2185  \n",
       "3    3.59  222.00  18.700  392.9529  5.9171  \n",
       "4    3.88  245.88  18.700  392.2296  5.3300  \n",
       "..    ...     ...     ...       ...     ...  \n",
       "501  1.00  286.43  21.000  390.4549  9.6700  \n",
       "502  1.00  273.00  19.329  396.9000  9.0800  \n",
       "503  3.72  312.44  21.000  389.8756  5.6400  \n",
       "504  1.00  243.71  21.000  393.4500  6.4800  \n",
       "505  1.00  315.70  18.969  396.9000  7.8800  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_missing_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对不同方法填补好的数据进行建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = []\n",
    "for i in [X_full,X_missing_0,X_missing_mean,X_missing_reg]:\n",
    "    rfg = RandomForestRegressor(random_state=0,n_estimators=100)\n",
    "    scores = cross_val_score(rfg,i,y_full,cv=5,scoring='neg_mean_squared_error').mean() \n",
    "    # 使用负均方误差\n",
    "    mse.append(scores * -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.571667100368845,\n",
       " 49.626793201980185,\n",
       " 40.848037216676374,\n",
       " 20.728257377829543]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('X_full', 21.571667100368845),\n",
       " ('X_missing_0', 49.626793201980185),\n",
       " ('X_missing_mean', 40.848037216676374),\n",
       " ('X_missing_reg', 20.728257377829543)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[*zip([\"X_full\",\"X_missing_0\",\"X_missing_mean\",\"X_missing_reg\"],mse)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用所得结果画出条形图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_labels = ['Full data',\n",
    "            'Zero Imputation',\n",
    "            'Mean Imputation',\n",
    "            'Regressor Imputation']\n",
    "colors = ['r', 'g', 'b', 'orange']\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = plt.subplot(111)\n",
    "for i in np.arange(len(mse)):\n",
    "    ax.barh(i, mse[i],color=colors[i], alpha=0.6, align='center')\n",
    "ax.set_title('Imputation Techniques with Boston Data')\n",
    "ax.set_xlim(left=np.min(mse) * 0.9,\n",
    "right=np.max(mse) * 1.1)\n",
    "ax.set_yticks(np.arange(len(mse)))\n",
    "ax.set_xlabel('MSE')\n",
    "ax.set_yticklabels(x_labels)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "825850a1542703e8330eb48918fb3db9db9b2154f7cb48e5f7ab1215ef3a88b8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
