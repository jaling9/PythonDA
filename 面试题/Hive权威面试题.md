<b>更多面试题，干货内容，可以查看此处，从编程工具到面试要点。
全流程编程工具集&学习集 https://www.johngo689.com/2617/，欢迎留言交流！</b> 
<i>以下面试题来自网络以及自己整理，如有侵权，请及时联系删除！</i> 
 *** 
[TOC]

### 1、Hive 的 metastore 的三种模式？
<ul><li><strong>内嵌Derby方式</strong><ul><li>这个是Hive默认的启动模式，一般用于单元测试。</li><li>这种存储方式有一个缺点：在同一时间只能有一个进程连 接使用数据库。</li></ul></li></ul><ul><li><strong>Local方式</strong><ul><li>本地MySQL</li></ul></li></ul><ul><li><strong>Remote方式</strong><ul><li>远程MySQL，一般常用此种方式</li></ul></li></ul>



### 2、Hive 内部表和外部表的区别？
<ul><li>建表时带有external关键字为外部表，否则为内部表</li><li>内部表和外部表建表时都可以自己指定location</li><li>删除表时，外部表不会删除对应的数据，只会删除元数据信息，内部表则会删除</li><li>其他用法是一样的</li></ul>



### 3、Hive 四种排序方式的区别？
<ol><li><strong>order by</strong><br />order by 是要对输出的结果进行全局排序，这就意味着只有一个reducer才能实现(多个reducer无法保证<br />全局有序)但是当数据量过大的时候，效率就很低。如果在严格模式下(hive.mapred.mode=strict),则必须配合limit使用；</li><li><strong>sort by</strong><br />sort by 不是全局排序，只是在进入到reducer之前完成排序，只保证了每个reducer中数据按照指定字段的有序性，是局部排序。配置mapred.reduce.tasks=[nums]可以对输出的数据执行归并排序。可以配合limit使 用，提高性能；</li><li><strong>distribute by</strong><br />distribute by 指的是按照指定的字段划分到不同的输出reduce文件中，和sort by一起使用时需要注意， distribute by 必须放在前面；</li><li><strong>cluster by</strong><br />cluster by 可以看做是一个特殊的distribute by+sort by，它具备二者的功能，但是只能实现倒序排序的方式, 不能指定排序规则为 asc 或者 desc。</li></ol>



### 4、Hive 中大表 join 小表的优化方法？
<p>在小表和大表进行join时，将<strong>小表放在前边</strong>，效率会高，<strong>hive会将小表进行缓存</strong>。</p>



### 5、Hive 中 join 都有哪些？
<p>Hive中除了支持和传统数据库中一样的内关联(JOIN)、左关联(LEFT JOIN)、右关联(RIGHT JOIN)、全关联</p><p>(FULL JOIN)，还支持左半关联(LEFT SEMI JOIN)</p><ol><li><strong>内关联(JOIN)</strong><br />只返回能关联上的结果。</li><li><strong>左外关联(LEFT [OUTER] JOIN)</strong><br />以LEFT [OUTER] JOIN关键字前面的表作为主表，和其他表进行关联，返回记录和主表的记录数一致，关联不上的字段置为 NULL。</li><li><strong>右外关联(RIGHT [OUTER] JOIN)</strong><br />和左外关联相反，以RIGTH [OUTER] JOIN关键词后面的表作为主表，和前面的表做关联，返回记录数和主表一致，关联不上的字段为NULL。</li><li><strong>全外关联(FULL [OUTER] JOIN)</strong> <br />以两个表的记录为基准，返回两个表的记录去重之和，关联不上的字段为NULL。</li><li><strong>LEFT SEMI JOIN</strong><br />以LEFT SEMI JOIN关键字前面的表为主表，返回主表的 KEY 也在副表中的记录</li><li><strong>笛卡尔积关联(CROSS JOIN) ：</strong>返回两个表的笛卡尔积结果，不需要指定关联键。</li></ol>



### 6、Hive SQL 是怎样解析成 MR job 的?
<ol><li>Hive使用Antlr实现语法解析.根据Antlr制定的SQL语法解析规则，完成SQL语句的词法/语法解析，将SQL转为抽 象语法树AST.</li><li>遍历AST，生成基本查询单元QueryBlock.QueryBlock是一条SQL最基本的组成单元，包括三个部分:输入 源，计算过程，输出.</li><li>遍历QueryBlock，生成OperatorTree.Hive最终生成的MapReduce任务，Map阶段和Reduce阶段均由 OperatorTree组成。Operator就是在Map阶段或者Reduce阶段完成单一特定的操作。QueryBlock生成 Operator Tree就是遍历上一个过程中生成的QB和QBParseInfo对象的保存语法的属性.</li><li>优化OperatorTree.大部分逻辑层优化器通过变换OperatorTree，合并操作符，达到减少MapReduceJob， 减少shuffle数据量的目的</li><li>OperatorTree生成MapReduceJob.遍历OperatorTree，翻译成MR任务.<ul><li>对输出表生成MoveTask</li><li>从OperatorTree的其中一个根节点向下深度优先遍历</li><li>ReduceSinkOperator标示Map/Reduce的界限，多个Job间的界限</li><li>遍历其他根节点，遇过碰到JoinOperator合并MapReduceTask</li><li>生成StatTask更新元数据</li><li>剪断Map与Reduce间的Operator的关系</li></ul></li><li>优化任务.使用物理优化器对MR任务进行优化，生成最终执行任务</li></ol>



### 7、Hive UDF 简单介绍！
<p>在Hive中，用户可以自定义一些函数，用于扩展HiveQL的功能，而这类函数叫做UDF(用户自定义函数)。</p><p>UDF分为两大类：<strong>UDAF(用户自定义聚合函数)和UDTF(用户自定义表生成函数)</strong>。</p><p><strong>Hive有两个不同的接口编写UDF程序。</strong></p><p><strong>一个是基础的UDF接口，一个是复杂的GenericUDF接口</strong>。</p><p>1. org.apache.hadoop.hive.ql.exec.UDF基础UDF的函数读取和返回基本类型，即Hadoop和Hive的基本类 型。如，Text、IntWritable、LongWritable、DoubleWritable等。</p><p>2. org.apache.hadoop.hive.ql.udf.generic.GenericUDF复杂的GenericUDF可以处理Map、List、Set类型。</p>



### 8、HMaster 宕机的时候，哪些操作还能正常工作？
<p>对表内数据的增删查改是可以正常进行的,因为hbase client 访问数据只需要通过 zookeeper 来找到 rowkey 的具体 region 位置即可。</p><p>但是对于创建表/删除表等的操作就无法进行了，因为这时候是需要HMaster介入，并且region的拆分、合并、迁移等操作也都无法进行了。</p>



### 9、Impala 和 hive 的查询有哪些区别？
<p><strong>Impala是基于Hive的大数据实时分析查询引擎。</strong></p><p>直接使用Hive的元数据库Metadata，意味着impala元数据都存储在Hive的metastore中。并且impala兼容Hive的sql解析，实现了Hive的SQL语义的子集，功能还在不断的完善中。</p><p><strong>Impala相对于Hive所使用的优化技术：</strong></p><p>1、没有使用 MapReduce进行并行计算，虽然MapReduce是非常好的并行计算框架，但它更多的面向批处理模式，而不是面向交互式的SQL执行。与 MapReduce相比:Impala把整个查询分成一执行计划树，而不是一连串的MapReduce任务，在分发执行计划后，Impala使用拉式获取数据的方式获取结果，把结果数据组成按执行树流式传递汇集，减少的了把中间结果写入磁盘的步骤，再从磁盘读取数据的开销。Impala使用服务的方式避免每次执行查询都需要启动的开销，即相比Hive没了MapReduce启动时间。</p><p><br />2、使用LLVM产生运行代码，针对特定查询生成特定代码，同时使用Inline的方式减少函数调用的开销，加快执行效率。</p><p><br />3、充分利用可用的硬件指令(SSE4.2)。</p><p><br />4、更好的IO调度，Impala知道数据块所在的磁盘位置能够更好的利用多磁盘的优势，同时Impala支持直接数据块读取和本地代码计算checksum。</p><p><br />5、通过选择合适的数据存储格式可以得到最好的性能(Impala支持多种存储格式)。</p><p><br />6、最大使用内存，中间结果不写磁盘，及时通过网络以stream的方式传递。</p><p>&nbsp;</p>



### 10、Hive SQL 最常见优化点！
<p>Hive的执行依赖于底层的MapReduce的作业，所以在执行效率上都是依赖于MR执行的一个效率。</p><p>所以，在学习了解MR原理是必要的，清楚了Hive底层的优化过程，会大大增加Hive的执行效率。Hive对于OLAP类型的应用有很大的局限性，它不适合需要立即返回查询结果的场景。然而，通过实施下面一系列的调优方法，Hive查询的性能会有大幅提高。</p><h2>1. 启动压缩</h2><p>压缩可以使磁盘上存储的数据量变小，例如，文本文件格式能够压缩40%甚至更高比例，这样可以通过降低I/O来提高查询速度。除非产生的数据用于外部系统，或者存在格式兼容性问题，建议总是启用压缩。</p><p>压缩与解压缩会消耗CPU资源，但Hive产生的MadReduce作业往往是I/O密集型的，因此CPU开销通常不是问题！</p><p>接下来，要想启用压缩，那么必须要知道所使用的hive版本所支持的压缩编码方式，下面的set命令可列出可用的编码器：（CDH5.13.1中的Hive）</p><blockquote><p><br /><br />hive&gt; set io.compression.codecs ;<br />io.compression.codecs=<br />org.apache.hadoop.io.compress.DefaultCodec,<br />org.apache.hadoop.io.compress.GzipCodec,<br />org.apache.hadoop.io.compress.BZip2Codec,<br />org.apache.hadoop.io.compress.DeflateCodec,<br />org.apache.hadoop.io.compress.SnappyCodec,<br />org.apache.hadoop.io.compress.Lz4Codec,<br />com.hadoop.compression.lzo.LzoCodec,<br />com.hadoop.compression.lzo.LzopCodec</p></blockquote><p>一个复杂的Hive查询在提交后，通常被转换为一系列中间阶段的MapReduce作业，Hive引擎将这些作业串联起来完成整个查询。可以将这些中间数据进行压缩。这里所说的中间数据指的是上一个MapReduce作业的输出，这些输出将被下一个MapReduce作业作为输入数据使用。我们可以在hive-site.xml文件中设置hive.exec.compress.intermediate属性以启用中间数据压缩</p><blockquote><p><br />&lt;property&gt;<br />    &lt;name&gt;hive.exec.compress.intermediate&lt;/name&gt;<br />    &lt;value&gt;true&lt;/value&gt;<br />    &lt;description&gt;<br />        ThiscontrolswhetherintermediatefilesproducedbyHivebetween<br />        multiplemap-reducejobsarecompressed.Thecompressioncodecandotheroptions<br />aredeterminedfromhadoopconfigvariablesmapred.output.compress*<br />    &lt;/description&gt;<br />&lt;/property&gt;<br />&lt;property&gt;<br />    &lt;name&gt;hive.intermediate.compression.codec&lt;/name&gt;<br />    &lt;value&gt;org.apache.hadoop.io.compress.SnappyCodec&lt;/value&gt;<br />    &lt;description/&gt;<br />&lt;/property&gt;<br />&lt;property&gt;<br />    &lt;name&gt;hive.intermediate.compression.type&lt;/name&gt;<br />    &lt;value&gt;BLOCK&lt;/value&gt;<br />    &lt;description/&gt;<br />&lt;/property&gt;</p></blockquote><p>也可以在Hive的客户端来进行设置这些属性</p><blockquote><p>hive&gt;set hive.exec.compress.intermediate=true;<br />hive&gt;set hive.intermediate.compression.codec=org.apache.hadoop.io.compress.SnappyCodec;<br />hive&gt;set hive.intermediate.compression.type=BLOCK;<br />hive&gt;</p></blockquote><p>当Hive将输出写入到表中时，输出内容同样可以进行压缩。我们可以设置hive.exec.compress.output属性启用最终输出压缩。</p><blockquote><p><br />&lt;property&gt;<br />    &lt;name&gt;hive.exec.compress.output&lt;/name&gt;<br />    &lt;value&gt;true&lt;/value&gt;<br />    &lt;/description&gt;<br />&lt;/property&gt;<br />或者：<br />hive&gt;set hive.exec.compress.output=true;<br />hive&gt;set mapreduce.output.fileoutputformat.compress=true;<br />hive&gt;set mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.SnappyCodec;<br />hive&gt;set mapreduce.output.fileoutputformat.compress.type=BLOCK;<br />hive&gt;</p></blockquote><p>&nbsp;</p><h2>2. 优化连接</h2><p>可以通过配置Map连接和倾斜连接的相关属性提升连接的查询公功能</p><h3>2.1 自动Map连接</h3><p>当连接一个大表和一个小表时，自动Map连接是一个非常有用的特性。如果启用了该特性，小表将保存在每个节点的本地缓        存中，并在Map阶段与大表进行连接。开启自动Map连接提供了两个好处。首先，将小表装进缓存将节省每个数据节点上的读取时间。其次，它避免了Hive查询中的倾斜连接，因为每个数据块的连接操作已经在Map阶段完成了。设置下面的属性启用自动Map连接属性。</p><blockquote><p><br />&lt;property&gt;<br />    &lt;name&gt;hive.auto.convert.join&lt;/name&gt;<br />    &lt;value&gt;true&lt;/value&gt;<br />&lt;/property&gt;<br />&lt;property&gt;<br />    &lt;name&gt;hive.auto.convert.join.noconditionaltask&lt;/name&gt; <br />    &lt;value&gt;true&lt;/value&gt;<br />&lt;/property&gt;<br />&lt;property&gt;<br />    &lt;name&gt;hive.auto.convert.join.noconditionaltask.size&lt;/name&gt; <br />    &lt;value&gt;10000000&lt;/value&gt; <br />&lt;/property&gt; <br />&lt;property&gt;<br />    &lt;name&gt;hive.auto.convert.join.use.nonstaged&lt;/name&gt;<br />    &lt;value&gt;true&lt;/value&gt;<br />&lt;/property&gt; </p></blockquote><p>-&gt; hive.auto.convert.join：是否启用基于输入文件的大小，将普通连接转化为Map连接的优化机制。<br />-&gt; hive.auto.convert.join.noconditionaltask：是否启用基于输入文件的大小，将普通连接转化为Map连接的优化机制。假设参与连接的表（或分区）有N个，如果打开这个参数，并且有N-1个表（或分区）的大小总和小于hive.auto.convert.join.noconditionaltask.size参数指定的值，那么会直接将连接转为Map连接。<br />-&gt; hive.auto.convert.join.noconditionaltask.size：如果hive.auto.convert.join.noconditionaltask是关闭的，则本参数不起作用。否则，如果参与连接的N个表（或分区）中的N-1个的总大小小于这个参数的值，则直接将连接转为Map连接。默认值为10MB。<br />-&gt;hive.auto.convert.join.use.nonstaged：对于条件连接，如果从一个小的输入流可以直接应用于join操作而不需要过滤或者投影，那么不需要通过MapReduce的本地任务在分布式缓存中预存。当前该参数在vectorization或tez执行引擎中不工作。</p><h3>2.2   倾斜连接</h3><p>两个大表连接时，会先基于连接键分别对两个表进行排序，然后连接它们。Mapper将特定键值的所有行发送给同一个Reducer。例如，表A的id列有1、2、3、4四个值，表B的id列有1、2、3三个值。查询语句如下：<br />        <br />        select A.id<br />        from A join B on A.id = B.id</p><p>一系列Mapper读取表中的数据并基于键值发送给Reducer。如id=1行进入Reducer R1，id=2的行进入Reducer R2等。这些Reducer产生A、B的交集并输出。Reducer R4只从A获取行，不会产生查询结果。</p><p>现在假设id=1的数据行是高度倾斜的，则R2和R3会很快完成，而R1需要很长时间，将成为整个查询的瓶颈。配置倾斜连接的相关属性可以有效优化倾斜连接。</p><blockquote><p><br />&lt;property&gt;<br />    &lt;name&gt;hive.optimize.skewjoin&lt;/name&gt;<br />    &lt;value&gt;true&lt;/value&gt;<br />&lt;/property&gt;<br />&lt;property&gt;<br />    &lt;name&gt;hive.skewjoin.key&lt;/name&gt;<br />    &lt;value&gt;100000&lt;/value&gt;<br />&lt;/property&gt;<br />&lt;property&gt;<br />    &lt;name&gt;hive.skewjoin.mapjoin.map.tasks&lt;/name&gt;<br />    &lt;value&gt;10000&lt;/value&gt;<br />&lt;/property&gt;<br />&lt;property&gt;<br />    &lt;name&gt;hive.skewjoin.mapjoin.min.split&lt;/name&gt;<br />    &lt;value&gt;33554432&lt;/value&gt;<br />&lt;/property&gt;</p></blockquote><p><br />-&gt; hive.optimize.skewjoin：是否为连接表中的倾斜键创建单独的执行计划。它基于存储在元数据中的倾斜键。在编译时，Hive为倾斜键和其他键值生成各自的查询计划。<br />-&gt; hive.skewjoin.key：决定如何确定连接中的倾斜键。在连接操作中，如果同一键值所对应的数据行数超过该参数值，则认为该键是一个倾斜连接键。<br />-&gt; hive.skewjoin.mapjoin.map.tasks：指定倾斜连接中，用于Map连接作业的任务数。该参数应该与hive.skewjoin.mapjoin.min.split一起使用，执行细粒度的控制。<br />-&gt; hive.skewjoin.mapjoin.min.split：通过指定最小split的大小，确定Map连接作业的任务数。该参数应该与hive.skewjoin.mapjoin.map.tasks一起使用，执行细粒度的控制。</p><h2>3. 避免使用order by全局排序</h2><p>Hive中使用order by子句实现全局排序。order by只用一个Reducer产生结果，对于大数据集，这种做法效率很低。如果不需要全局有序，则可以使用sort by子句，该子句为每个reducer生成一个排好序的文件。如果需要控制一个特定数据行流向哪个reducer，可以使用distribute by子句</p><p>属于一个dept的数据会分配到同一个reducer进行处理，同一个dept的所有记录按照id、name列排序。最终的结果集是全局有序的。在10.3节还会讨论Hive中几种不同的数据排序方法。</p><p>注意：这里要区别出来cluster by 和 distribute by … sort by 的区别！！！</p><p>&nbsp;</p><h2>4. 启动Tez执行引擎</h2><p>使用Tez执行引擎代替传统的MapReduce引擎会大幅提升Hive查询的性能。在安装好Tez后，配置hive.execution.engine属性指定执行引擎。</p><blockquote><p>&lt;property&gt;<br />    &lt;name&gt;hive.execution.engine&lt;/name&gt;<br />    &lt;value&gt;tez&lt;/value&gt;<br />    &lt;description&gt;&lt;/description&gt;<br />&lt;/property&gt;</p></blockquote><p>&nbsp;</p><h2>5. 优化limit操作</h2><p>默认时limit操作仍然会执行整个查询，然后返回限定的行数。在有些情况下这种处理方式很浪费，因此可以通过设置下面的属性避免此行为。</p><blockquote><p><br />&lt;property&gt;<br />    &lt;name&gt;hive.limit.optimize.enable&lt;/name&gt;<br />    &lt;value&gt;true&lt;/value&gt;<br />&lt;/property&gt;<br />&lt;property&gt;<br />    &lt;name&gt;hive.limit.row.max.size&lt;/name&gt;<br />    &lt;value&gt;100000&lt;/value&gt;<br />&lt;/property&gt;<br />&lt;property&gt;<br />    &lt;name&gt;hive.limit.optimize.limit.file&lt;/name&gt;<br />    &lt;value&gt;10&lt;/value&gt;<br />&lt;/property&gt;<br />&lt;property&gt;<br />    &lt;name&gt;hive.limit.optimize.fetch.max&lt;/name&gt;<br />    &lt;value&gt;50000&lt;/value&gt;<br />&lt;/property&gt;</p></blockquote><p><br />说明：<br />-&gt; hive.limit.optimize.enable：是否启用limit优化。当使用limit语句时，对源数据进行抽样。<br />-&gt; hive.limit.row.max.size：在使用limit做数据的子集查询时保证的最小行数据量。<br />-&gt; hive.limit.optimize.limit.file：在使用limit做数据子集查询时，采样的最大文件数。<br />-&gt; hive.limit.optimize.fetch.max：使用简单limit数据抽样时，允许的最大行数。</p><p>&nbsp;</p><h2>6. 启用并行执行</h2><p>每条HiveQL语句都被转化成一个或多个执行阶段，可能是一个MapReduce阶段、采样阶段、归并阶段、限制阶段等。默认时，Hive在任意时刻只能执行其中一个阶段。如果组成一个特定作业的多个执行阶段是彼此独立的，那么它们可以并行执行，从而整个作业得以更快完成。通过设置下面的属性启用并行执行。</p><blockquote><p>&lt;property&gt;<br />    &lt;name&gt;hive.exec.parallel&lt;/name&gt;<br />    &lt;value&gt;true&lt;/value&gt;<br />&lt;/property&gt;<br />&lt;property&gt;<br />    &lt;name&gt;hive.exec.parallel.thread.number&lt;/name&gt;<br />    &lt;value&gt;8&lt;/value&gt;<br />&lt;/property&gt;<br />-&gt; hive.exec.parallel：是否并行执行作业。<br />-&gt; hive.exec.parallel.thread.number：最多可以并行执行的作业数。</p></blockquote><p>&nbsp;</p><h2>7. 启用严格模式</h2><p>Hive提供了一个严格模式，可以防止用户执行那些可能产生负面影响的查询。通过设置下面的属性启用MapReduce严格模式。</p><blockquote><p><br />&lt;property&gt;<br />    &lt;name&gt;hive.mapred.mode&lt;/name&gt;<br />    &lt;value&gt;strict&lt;/value&gt;<br />&lt;/property&gt;</p></blockquote><p><br />严格模式禁止3种类型的查询:<br />-&gt; 对于分区表，where子句中不包含分区字段过滤条件的查询语句不允许执行<br />-&gt; 对于使用了order by子句的查询，要求必须使用limit子句，否则不允许执行<br />-&gt; 限制笛卡尔积查询<br />使用单一Reduce执行多个group by<br />        通过为group by操作开启单一reduce任务属性，可以将一个查询中的多个group by操作联合在一起发送给单一MapReduce作业。</p><blockquote><p><br />&lt;property&gt;<br />    &lt;name&gt;hive.multigroupby.singlereducer&lt;/name&gt;<br />    &lt;value&gt;true&lt;/value&gt;<br />    &lt;description&gt;&lt;/description&gt;<br />&lt;/property&gt;</p></blockquote><p>&nbsp;</p><p>&nbsp;</p><p>&nbsp;</p><h2>8. 控制并行Reduce任务</h2><p> Hive通过将查询划分成一个或多个MapReduce任务达到并行的目的。确定最佳的mapper个数和reducer个数取决于多个变量，例如输入的数据量以及对这些数据执行的操作类型等。如果有太多的mapper或reducer任务，会导致启动、调度和运行作业过程中产生过多的开销，而如果设置的数量太少，那么就可能没有充分利用好集群内在的并行性。对于一个Hive查询，可以设置下面的属性来控制并行reduce任务的个数</p><blockquote><p><br />&lt;property&gt;<br />    &lt;name&gt;hive.exec.reducers.bytes.per.reducer&lt;/name&gt;<br />    &lt;value&gt;256000000&lt;/value&gt;<br />&lt;/property&gt;<br />&lt;property&gt;<br />    &lt;name&gt;hive.exec.reducers.max&lt;/name&gt;<br />    &lt;value&gt;1009&lt;/value&gt;<br />&lt;/property&gt;</p></blockquote><p><br />-&gt; hive.exec.reducers.bytes.per.reducer：每个reducer的字节数，默认值为256MB。Hive是按照输入的数据量大小来确定reducer个数的。例如，如果输入的数据是1GB，将使用4个reducer。<br />-&gt; hive.exec.reducers.max：将会使用的最大reducer个数。</p><p>&nbsp;</p><p><strong>注意：不断清晰MR流程，以及HIVE转化为MR的过程，才能更好的去优化！</strong></p>


